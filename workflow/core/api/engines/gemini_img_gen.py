import re
from typing import List
from pydantic import Field
import google.generativeai as genai
# from google.generativeai.vision_models import ImageGenerationModel
from workflow.core.data_structures import ModelConfig, ApiType, FileContentReference, MessageDict, ContentType, FileType, References, FunctionParameters, ParameterDefinition
from workflow.core.api.engines.api_engine import APIEngine

class GeminiImageGenerationEngine(APIEngine):
    input_variables: FunctionParameters = Field(
        default=FunctionParameters(
            type="object",
            properties={
                "prompt": ParameterDefinition(
                    type="string",
                    description="A text description of the desired image(s)."
                ),
                "n": ParameterDefinition(
                    type="integer",
                    description="The number of images to generate.",
                    default=1
                ),
                "size": ParameterDefinition(
                    type="string",
                    description="The size of the generated images.",
                    default="1024x1024"
                ),
                "quality": ParameterDefinition(
                    type="string",
                    description="The quality of the image generation.",
                    default="standard"
                ),
                "model": ParameterDefinition(
                    type="string",
                    description="The model to use for image generation.",
                    default="imagen-3.0-generate-001"
                )
            },
            required=["prompt"]
        )
    )
    required_api: ApiType = Field(ApiType.LLM_MODEL, title="The API engine required")

    def generate_filename(self, prompt: str, model: str, index: int) -> str:
        """
        Generate a descriptive filename based on the prompt and model.
        """
        sanitized_prompt = re.sub(r'[^\w\s-]', '', prompt.lower())
        truncated_prompt = '_'.join(sanitized_prompt.split())
        return f"{truncated_prompt[:70]}_{model}_{index}.png"

    async def generate_api_response(self, api_data: ModelConfig, prompt: str, n: int = 1, size: str = "1024x1024", quality: str = "standard", model: str = "imagen-3.0-generate-001") -> References:
        """
        Generates images using Google's Gemini model.
        """
        genai.configure(api_key=api_data.api_key)
        # imagen = ImageGenerationModel(model)

        # Map size to aspect ratio (this is an approximation, adjust as needed)
        size_to_aspect_ratio = {
            "1024x1024": "1:1",
            "1024x1792": "9:16",
            "1792x1024": "16:9",
        }
        aspect_ratio = size_to_aspect_ratio.get(size, "1:1")

        # Map quality to a boolean (standard -> False, hd -> True)
        is_hd = quality.lower() == "hd"
        return References(files=[])
        ## Gemini is trash, their docs like, seems its impossible for Google to create a simple, unified, API for their AI services. 
        # try:
        #     result = imagen.generate_images(
        #         prompt=prompt,
        #         number_of_images=n,
        #         aspect_ratio=aspect_ratio,
        #         hd=is_hd
        #     )

        #     file_references: List[FileContentReference] = []
        #     for index, image in enumerate(result.images):
        #         filename = self.generate_filename(prompt, model, index + 1)
        #         # Convert the image to base64
        #         import io
        #         import base64
        #         buffered = io.BytesIO()
        #         image._pil_image.save(buffered, format="PNG")
        #         img_str = base64.b64encode(buffered.getvalue()).decode()

        #         file_references.append(FileContentReference(
        #             filename=filename,
        #             type=FileType.IMAGE,
        #             content=img_str,
        #             transcript=MessageDict(
        #                 role='tool', 
        #                 content=f"Image generated by model {model}. \nPrompt: '{prompt}' \nSize: {size}", 
        #                 type=ContentType.TEXT, 
        #                 generated_by='tool', 
        #                 creation_metadata={
        #                     "prompt": prompt, 
        #                     "size": size,
        #                     "quality": quality,
        #                     "model": model
        #                 }
        #             )
        #         ))

        #     return References(files=file_references)
        # except Exception as e:
        #     raise Exception(f"Error in Gemini image generation API call: {str(e)}")